from PIL import Image
from PIL.Image import Image as PILImage
from typing import Any
from .caller_registry import register_caller
from google import genai
from google.genai import types
from google.genai.types import Image as GoogleImage
from openai import OpenAI
import os


def encode_image_to_base64(image_path: str) -> str:
    import base64
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def base64_to_PILImage(base64_image_url: str) -> PILImage:
    import base64
    from io import BytesIO
    base64_data = base64_image_url.split(",")[1]
    image_bytes = base64.b64decode(base64_data)
    pil_image = Image.open(BytesIO(image_bytes))
    return pil_image


class LLMCaller:
    def generate_text(self, model: str, prompt: str, **kwargs: Any) -> str:
        raise NotImplementedError

    def understand_image(
        self, model: str, prompt: str, image_path: str, **kwargs: Any
    ) -> str:
        raise NotImplementedError

    def generate_image(
        self, model: str, prompt: str, **kwargs: Any
    ) -> GoogleImage | PILImage:
        raise NotImplementedError


@register_caller("google")
class GoogleCaller(LLMCaller):
    def __init__(self) -> None:
        self._client = genai.Client()

    def generate_text(self, model: str, prompt: str, **kwargs: Any) -> str:
        response = self._client.models.generate_content(model=model, contents=prompt)
        return response.text

    def understand_image(
        self, model: str, prompt: str, image_path: str, **kwargs: Any
    ) -> str:
        if prompt is None:
            raise ValueError("Prompt cannot be None")
        with open(image_path, "rb") as f:
            image_bytes = f.read()
        response = self._client.models.generate_content(
            model=model,
            contents=[
                types.Part.from_bytes(data=image_bytes, mime_type="image/jpeg"),
                prompt,
            ],
        )
        return response.text

    def generate_image(self, model: str, prompt: str, **kwargs: Any) -> GoogleImage:
        response = self._client.models.generate_content(
            model=model,
            contents=[prompt],
        )
        image = None
        for part in response.parts:
            if part.inline_data is not None:
                image = part.as_image()
        if image is None:
            raise ValueError("No image generated by Google model")
        return image


@register_caller("openrouter")
class OpenrouterCaller(LLMCaller):
    def __init__(self) -> None:
        self._client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
        )

    def generate_text(self, model: str, prompt: str, **kwargs: Any) -> str:
        response = self._client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
        )
        response = response.choices[0].message.content
        return response

    def understand_image(
        self, model: str, prompt: str, image_path: str, **kwargs: Any
    ) -> str:
        base64_image = encode_image_to_base64(image_path)
        response = self._client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
        )
        response = response.choices[0].message.content
        return response

    def generate_image(self, model: str, prompt: str, **kwargs: Any) -> PILImage:
        response = self._client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            extra_body={"modalities": ["image", "text"]},
        )
        pil_image = None
        response = response.choices[0].message
        if response.images:
            for image in response.images:
                image_url = image["image_url"]["url"]
                pil_image = base64_to_PILImage(base64_image_url=image_url)
        if pil_image is not None:
            return pil_image
        else:
            raise ValueError("No image generated")


@register_caller("replicate")
class ReplicateCaller(LLMCaller):
    def __init__(self) -> None:
        pass

    def generate_text(self, model: str, prompt: str, **kwargs: Any) -> str:
        import replicate
        input = {"prompt": prompt}
        output = replicate.run(model, input=input)
        return "".join(output)

    def generate_image(self, model: str, prompt: str, **kwargs: Any) -> PILImage:
        import replicate
        import requests
        from PIL import Image
        from io import BytesIO

        if model == "openai/gpt-image-1.5":
            input = {"prompt": prompt, "quality": kwargs.get("quality", "medium")}
        else:
            input = {"prompt": prompt}

        response = replicate.run(model, input=input)

        if model in [
            "qwen/qwen-image",
            "bytedance/seedream-4.5",
            "openai/gpt-image-1.5",
            "minimax/image-01",
        ]:
            image_url = response[0].url
        else:
            image_url = response.url

        image_response = requests.get(image_url)
        image_response.raise_for_status()
        pil_image = Image.open(BytesIO(image_response.content))
        return pil_image
